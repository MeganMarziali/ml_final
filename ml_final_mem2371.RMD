---
title: "Machine Learning Final"
author: "Megan Marziali"
date: "3/25/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(caret)
library(rpart.plot)
library(Amelia)
library(arsenal)
library(factoextra)
library(cluster)

set.seed(100)
```

# Part 1: Dietary patterns using unsupervised analysis

## Question 1: Construct a research question

The goal of this unsupervised analysis will be to develop classes of dietary patterns among women during pregnancy. These classes will be used as an exposure in future analyses, aiming to predict whether dietary patterns during pregnancy are predictive of postpartum mental health systems (such as post-partum depression). This is a predictive research question.

## Question 2: Running appropriate unsupervised analysis

```{r}
diet.data = 
  read.csv("./data/diet_data.csv", header = TRUE) %>% 
  select(
    "h_cereal_preg_Ter",
    "h_dairy_preg_Ter",
    "h_fastfood_preg_Ter",
    "h_fish_preg_Ter",
    "h_fruit_preg_Ter",
    "h_legume_preg_Ter",
    "h_meat_preg_Ter",
    "h_veg_preg_Ter",
  )
```

I restricted the data to variables which assessed fdietary patterns during pregnancy. The total dataset is comprised of 1301 observations, and 8 variables.

```{r}
missmap(diet.data, main = "Missing values vs observed")
```

I used missmap to determine if there are any missing observations, which there are not. To determine clusters within the data, a hierarchical cluster analysis with the complete linkage method will be carried out.

```{r}
set.seed(100)

# Create Dissimilarity matrix
diss.matrix = dist(diet.data, method = "euclidean")

#Identifying the optimal number of clusters given complete linkage method
gap_stat_c = clusGap(diet.data, FUN = hcut, hc_method = "complete", K.max = 10, B = 50)
fviz_gap_stat(gap_stat_c)

#Characterizing the clusters
clusters.c = hcut(diet.data, k = 2, hc_func = "hclust", hc_method = "complete", hc_metric = "euclidian")

clusters.c$size
fviz_dend(clusters.c, rect = TRUE)
fviz_cluster(clusters.c)
```

The optimal number of clusters within this data is *2* clusters. There are 840 observations in the first cluster, and 461 observations in the second cluster.

```{r}
input.feature.vals = cbind(diet.data, cluster = clusters.c$cluster)
input.feature.vals %>%
 group_by(cluster) %>%
 summarise_all(mean) %>% 
  knitr::kable()
```

The first cluster has less cereal consumed during pregnancy by mothers than the second cluster; respondents also consumed slightly more dairy, fast food, and fish. Those in the second cluster consumed more cereal and slightly more fruit and meats. Both clusters consumed approximately the same amount of vegetables.

# Part 2: Choose your own supervised adventure

## Research question

The goal of this analysis is to generate hypotheses regarding social capital, nutrient intake and toxic metals during pregnancy on child externalizing and internalizing behaviors. This hypotheses generating analysis will guide future research on the role of social capital on child behaviors, and whether interactions between nutrient intake and toxic metals are salient for child behaviors.

## Loading and preparing data

Loading data into single data frame.

```{r dataprep, message = FALSE, warning = FALSE}
#Load data using path of where file is stored
load("./data/exposome.RData")

#Merge all data frames into a single data frame. FYI, this is just a shortcut by combining baseR with piping from tidyverse. There are other ways of merging across three data frames that are likely more elegant.

studydata = 
  merge(exposome,phenotype,by = "ID") %>% 
  merge(covariates, by = "ID")

#Strip off ID Variable
studydata$ID = NULL
```

Data cleaning and selecting relevant features to research question.

```{r message = FALSE, warning = FALSE}
studydata  = studydata %>% 
  select(e3_alcpreg_yn_None,
         h_cereal_preg_Ter,
         h_dairy_preg_Ter,
         h_fastfood_preg_Ter,
         h_fish_preg_Ter,
         h_folic_t1_None,
         h_fruit_preg_Ter,
         h_legume_preg_Ter,
         h_meat_preg_Ter,
         h_veg_preg_Ter,
         hs_as_m_Log2,
         hs_cd_m_Log2,
         hs_co_m_Log2,
         hs_cs_m_Log2,
         hs_cu_m_Log2,
         hs_hg_m_Log2,
         hs_mn_m_Log2,
         hs_mo_m_Log2,
         hs_pb_m_Log2,
         hs_tl_mdich_None,
         hs_dde_madj_Log2,
         hs_ddt_madj_Log2,
         hs_hcb_madj_Log2,
         hs_pcb118_madj_Log2,
         hs_pcb138_madj_Log2,
         hs_pcb153_madj_Log2,
         hs_pcb170_madj_Log2,
         hs_pcb180_madj_Log2,
         hs_sumPCBs5_madj_Log2,
         hs_dep_madj_Log2,
         hs_detp_madj_Log2,
         hs_dmp_madj_Log2,
         hs_dmtp_madj_Log2,
         hs_pbde153_madj_Log2,
         hs_pbde47_madj_Log2,
         hs_pfhxs_m_Log2,
         hs_pfna_m_Log2,
         hs_pfoa_m_Log2,
         hs_pfos_m_Log2,
         hs_pfunda_m_Log2,
         hs_bpa_madj_Log2,
         hs_bupa_madj_Log2,
         hs_etpa_madj_Log2,
         hs_mepa_madj_Log2,
         hs_oxbe_madj_Log2,
         hs_prpa_madj_Log2,
         hs_trcs_madj_Log2,
         hs_mbzp_madj_Log2,
         hs_mecpp_madj_Log2,
         hs_mehhp_madj_Log2,
         hs_mehp_madj_Log2,
         hs_meohp_madj_Log2,
         hs_mep_madj_Log2,
         hs_mibp_madj_Log2,
         hs_mnbp_madj_Log2,
         hs_ohminp_madj_Log2,
         hs_oxominp_madj_Log2,
         hs_sumDEHP_madj_Log2,
         hs_cotinine_mcat_None,
         FAS_cat_None,
         hs_contactfam_3cat_num_None,
         hs_hm_pers_None,
         hs_participation_3cat_None,
         hs_Gen_Tot
         ) 

data.rec = studydata %>% 
  mutate(
    behav = cut(hs_Gen_Tot, 
                breaks = c(-Inf, 60, Inf),
                labels = c("0", "1"))
  ) %>% 
  select(-hs_Gen_Tot) %>% 
  select(everything(), behav)
```

Data exploration.

```{r message = FALSE, warning = FALSE, results = "asis"}
# Investigating missing data
missmap(studydata)

# No missingness observed.

# Exploring continuous/categorical variables of interest
table.1 = tableby(~ behav + FAS_cat_None + hs_contactfam_3cat_num_None +
                    hs_sumDEHP_madj_Log2 + hs_ohminp_madj_Log2 + hs_mibp_madj_Log2 + hs_mehp_madj_Log2,
                  data = data.rec,
        numeric.stats = c("mean","median", "range"))
summary(table.1, text = TRUE)
```

The data is unbalanced.

Partitioning data.

```{r message = FALSE, warning = FALSE}
set.seed(100)

#Partition data for use in demonstration
train.indices = createDataPartition(y = data.rec$behav, p = 0.7,list = FALSE)
training = data.rec[train.indices, ]
testing = data.rec[-train.indices, ]
```

## Using LASSO for feature selection

```{r, warning = FALSE, message = FALSE}
set.seed(100)

#Create grid to search lambda
lambda = 10^seq(-3,3, length = 100)

lasso.m = train(
  behav ~., 
  data = training, 
  method = "glmnet", 
  trControl = trainControl("cv", number = 10, sampling = "down"), 
  tuneGrid = expand.grid(alpha = 0, lambda = lambda)
)

#Print the values of alpha and lambda that gave best prediction
lasso.m$bestTune

#Print all of the options examined
lasso.m$results

# Model coefficients
coef(lasso.m$finalModel, lasso.m$bestTune$lambda)
varImp(lasso.m)

# Make predictions
pred.lasso = predict(lasso.m, training)
pred.lasso.prob = predict(lasso.m, training, type = "prob")

# Model prediction performance
eval.results = confusionMatrix(pred.lasso, training$behav, positive = "1")
print(eval.results)

#Accuracy of this model is 0.62
```

## Final accuracy testing

```{r message = FALSE, warning = FALSE}
set.seed(100)

# Using best fit model from above with testing data
pred.lasso.f = predict(lasso.m, testing)
pred.lasso.f.prob = predict(lasso.m, testing, type = "prob")

# Evaluating in testing data with confusion matrix
eval.results = confusionMatrix(pred.lasso.f, testing$behav, positive = "1")
print(eval.results)
```

Final accuracy testing shows that the accuracy of this model is 0.63.


